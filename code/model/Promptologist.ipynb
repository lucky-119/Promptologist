{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqJ54iqhimU4"
      },
      "source": [
        "# Installations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBvuDmucfW6s"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install langid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrd1PFkoisbs"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hd55SVD_iVj_"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from datasets import load_from_disk\n",
        "import langid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aim3bFOz6ksO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive # Link your drive if you are a colab user\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t3lDVccQFlP"
      },
      "outputs": [],
      "source": [
        "import os.path as path\n",
        "if path.exists(\"/content\"):\n",
        "  !sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "  !sudo apt-get update -qq 2>&1 > /dev/null\n",
        "  !sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "  !google-drive-ocamlfuse\n",
        "\n",
        "  !sudo apt-get install -qq w3m # to act as web browser\n",
        "  !xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "  %cd /content\n",
        "  !mkdir drive\n",
        "  %cd drive\n",
        "  !mkdir MyDrive\n",
        "  %cd ..\n",
        "  %cd ..\n",
        "  !google-drive-ocamlfuse -o nonempty /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J3JoqzggTTvQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "batchSize = 16\n",
        "blockSize = 32\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "with open('/content/trainFinal.txt', 'r', encoding='utf-8') as f:\n",
        "    trainData = f.read()\n",
        "\n",
        "with open('/content/valid.txt', 'r', encoding='utf-8') as f:\n",
        "    validData = f.read()\n",
        "\n",
        "with open('/content/testFinal.txt', 'r', encoding='utf-8') as f:\n",
        "    testData = f.read()\n",
        "\n",
        "chars = sorted(list(set(trainData)))\n",
        "vocabSize = len(chars)\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encodeText = lambda s: [stoi[c] for c in s]\n",
        "decodeText = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "# Train and test splits\n",
        "trainData = torch.tensor(encodeText(trainData), dtype=torch.long)\n",
        "valData = torch.tensor(encodeText(validData), dtype=torch.long)\n",
        "testData = torch.tensor(encodeText(testData), dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1mct_su9TX78"
      },
      "outputs": [],
      "source": [
        "def getBatch(tvt):\n",
        "    if(tvt == 'train'):\n",
        "      data = trainData\n",
        "    elif(tvt == 'test'):\n",
        "      data = testData\n",
        "    else:\n",
        "      data = valData\n",
        "    ix = torch.randint(len(data)-blockSize,(batchSize,))\n",
        "    x = torch.stack([data[i:i+blockSize] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+blockSize+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimateLoss():\n",
        "    model.eval()\n",
        "    out = {}\n",
        "    for tvt in ['train', 'val', 'test']:\n",
        "        losses = torch.zeros(evaluationIterations)\n",
        "        for k in range(evaluationIterations):\n",
        "            X, Y = getBatch(tvt)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[tvt] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yEMtFp8M6Kcy"
      },
      "outputs": [],
      "source": [
        "class pBLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(pBLSTM, self).__init__()\n",
        "        self.blstm = nn.LSTM(input_size*2, hidden_size, num_layers = num_layers, batch_first=True, dropout=0.2)\n",
        "\n",
        "    def forward(self, x_packed):\n",
        "        x_pad, x_lens = torch.nn.utils.rnn.pad_packed_sequence(x_packed, batch_first = True)\n",
        "        x, x_lens = self.trunc_reshape(x_pad,x_lens)\n",
        "        x = torch.nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first = True, enforce_sorted = False)\n",
        "\n",
        "        return self.blstm(x)\n",
        "\n",
        "    def trunc_reshape(self, x, x_lens):\n",
        "        if x.shape[1]%2:\n",
        "          x = x[:,:-1,:].reshape(x.shape[0], x.shape[1] // 2, x.shape[2] * 2)\n",
        "          x_lens-=1\n",
        "        else:\n",
        "          x = x.reshape(x.shape[0], x.shape[1] // 2, x.shape[2] * 2)\n",
        "        x_lens //= 2\n",
        "\n",
        "        return x, x_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fxyC4qdmThJn"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, headSize):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(numberOfEmbeddings, headSize, bias=False)\n",
        "        self.query = nn.Linear(numberOfEmbeddings, headSize, bias=False)\n",
        "        self.value = nn.Linear(numberOfEmbeddings, headSize, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(blockSize, blockSize)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, headSize):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(headSize) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(numberOfEmbeddings, numberOfEmbeddings)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    def __init__(self, numberOfEmbeddings):\n",
        "        super().__init__()\n",
        "        self.net1 = nn.Sequential(\n",
        "            nn.Linear(numberOfEmbeddings, 4 * numberOfEmbeddings),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2)\n",
        "        )\n",
        "        self.con = nn.Sequential(\n",
        "            torch.nn.Conv1d(2*numberOfEmbeddings,numberOfEmbeddings*2,kernel_size=1,stride=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=0.2),\n",
        "            torch.nn.Conv1d(numberOfEmbeddings*2,numberOfEmbeddings*4,kernel_size=1,stride=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=0.2),\n",
        "            torch.nn.Conv1d(numberOfEmbeddings*4,4*numberOfEmbeddings,kernel_size=1,stride=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=0.2),\n",
        "        )\n",
        "        self.pblstm= nn.LSTM(input_size = 4 * numberOfEmbeddings, hidden_size = numberOfEmbeddings, num_layers = 2, bidirectional = True, batch_first = True, dropout=dropout).to(device)\n",
        "        self.net2 = nn.Sequential(\n",
        "            nn.Linear(4*numberOfEmbeddings, numberOfEmbeddings),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net1(x)\n",
        "        x_len = torch.tensor([a.shape[0] for a in x])\n",
        "        x_packed = torch.nn.utils.rnn.pack_padded_sequence(x,x_len,batch_first=True,enforce_sorted=False)# TODO\n",
        "        lstm_out, _ = self.pblstm(x_packed.to(device))# TODO\n",
        "        output, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm_out,batch_first=True)# TODO\n",
        "        output = self.con(output.permute(0,2,1))\n",
        "        output = self.net2(output.permute(0,2,1))\n",
        "        return output\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, numberOfEmbeddings, numberOfHeads):\n",
        "        super().__init__()\n",
        "        headSize = numberOfEmbeddings // numberOfHeads\n",
        "        self.sa = MultiHeadAttention(numberOfHeads, headSize)\n",
        "        self.ffwd = FeedFoward(numberOfEmbeddings)\n",
        "        self.ln1 = nn.LayerNorm(numberOfEmbeddings)\n",
        "        self.ln2 = nn.LayerNorm(numberOfEmbeddings)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln1(x + self.sa(x))\n",
        "        x = self.ln2(x + self.ffwd(x))\n",
        "        return x\n",
        "\n",
        "class NgramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocabSize, numberOfEmbeddings)\n",
        "        self.position_embedding_table = nn.Embedding(blockSize, numberOfEmbeddings)\n",
        "        self.blocks = nn.Sequential(*[Block(numberOfEmbeddings, numberOfHeads=numberOfHeads) for _ in range(numberOfLayers)])\n",
        "        self.ln_f = nn.LayerNorm(numberOfEmbeddings)\n",
        "        self.lm_head = nn.Linear(numberOfEmbeddings, vocabSize)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, maxNewTokens):\n",
        "\n",
        "        for _ in range(maxNewTokens):\n",
        "            idx_cond = idx[:, -blockSize:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "iD4_4wcxTNf7"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    torch.save(\n",
        "        {'model_state_dict'         : model.state_dict(),\n",
        "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'     : None,\n",
        "         metric[0]                  : metric[1],\n",
        "         'epoch'                    : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, metric= 'valid_acc', optimizer= None, scheduler= None):\n",
        "\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer != None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler != None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch   = checkpoint['epoch']\n",
        "    metric  = checkpoint[metric]\n",
        "\n",
        "    return model, optimizer, scheduler, epoch, metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ_gyT-G1R-P"
      },
      "outputs": [],
      "source": [
        "#Training\n",
        "lowest_val_loss=100000\n",
        "epochs = 1000000\n",
        "evalInterval = 100\n",
        "learning_rate = 1e-3\n",
        "evaluationIterations = 200\n",
        "numberOfEmbeddings = 64\n",
        "numberOfHeads = 4\n",
        "numberOfLayers = 4\n",
        "dropout = 0.1\n",
        "epoch_model_path = '/content/Running_Model_Checkpoint'\n",
        "best_epoch_model_path = '/content/Best_Model_Checkpoint'\n",
        "model = NgramLanguageModel().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "model, optimizer, scheduler, epoch, lowest_val_loss = load_model(epoch_model_path, model, 'low_val_loss', optimizer)\n",
        "m = model.to(device)\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    if(e % evalInterval == 0 or e == epochs - 1):\n",
        "        losses = estimateLoss()\n",
        "        print(f\"Step {e}: Train Loss: {losses['train']:.4f}, Val Loss: {losses['val']:.4f}\")\n",
        "        save_model(model, optimizer, None, ['low_val_loss', losses['val']], e, epoch_model_path)\n",
        "        if(losses['val']<lowest_val_loss):\n",
        "          lowest_val_loss=losses['val']\n",
        "          print('Saving Model')\n",
        "          save_model(model, optimizer, None, ['low_val_loss', losses['val']], e, best_epoch_model_path)\n",
        "\n",
        "    xb, yb = getBatch('train')\n",
        "\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXdHX_B2_6u5"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "#epoch_model_path = 'Running_Model_Checkpoint'\n",
        "best_epoch_model_path = '/content/Best_Model_Checkpoint'\n",
        "model = NgramLanguageModel().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "model, optimizer, scheduler, epoch, lowest_val_loss = load_model(best_epoch_model_path, model, 'low_val_loss', optimizer)\n",
        "m = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3VoMJbkRYS-"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate\n",
        "!pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGmJeXYaR5Yi"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import json\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "\n",
        "bertScore = load(\"bertscore\")\n",
        "\n",
        "with open('/content/test.json', 'r') as json_file:\n",
        "    data = [json.loads(line) for line in json_file]\n",
        "formatted_rows = [f\"Patient: {row['input']}\\nDoctor: {row['output']}\\n\" for row in data]\n",
        "formatted_text = ''.join(formatted_rows)\n",
        "\n",
        "a = formatted_text.split('\\n')[::2]\n",
        "b = formatted_text.split('\\n')[1::2]\n",
        "\n",
        "newText = list(zip(a,b))\n",
        "\n",
        "score=0.0\n",
        "predictions=[]\n",
        "references=[]\n",
        "bleuscores=[]\n",
        "for i in range(len(newText)):\n",
        "  data = torch.tensor(encodeText(newText[i][0]), dtype=torch.long)\n",
        "  context = data.reshape(-1, 1).to(device)\n",
        "  output=decodeText(m.generate(context, maxNewTokens=len(newText[i][1]))[0].tolist())\n",
        "  predictions.append(output)\n",
        "  references.append(newText[i][1])\n",
        "  bscore=sentence_bleu(newText[i][1].split(),output.split())\n",
        "  bleuscores.append(bscore)\n",
        "bleuscoresnp=np.array(bleuscores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R__Ma2kEXsqp"
      },
      "outputs": [],
      "source": [
        "losses = estimateLoss()\n",
        "print(\"Test Cross Entropy Loss: \",losses['test'])\n",
        "bleuscoresnp=np.array(bleuscores)\n",
        "bscore=bertScore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "print(\"Bert Precision: \", np.average(bscore['precision']))\n",
        "print(\"Bert Recall: \", np.average(bscore['recall']))\n",
        "print(\"Bert F1: \", np.average(bscore['f1']))\n",
        "print(\"Bleu Score: \", np.average(bleuscoresnp))\n",
        "#Bleu Score not valid and a good evaluation metric in our case since it exactly matches each word of both the prediction and references outputs\n",
        "#Bert Score is a good indicator since it takes into consideration a pretrained bert along with cosine similarity to evaluate the outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "euj6r0Dv_BRr"
      },
      "outputs": [],
      "source": [
        "data = torch.tensor(encodeText(\"So last week I started itching real bad, especially in my legs. I started noticing some bruising (and there were a lot of bruises, BIG bruises) where I scratched. I didnt think I was scratching so hard and Ive never bruised like this before whenever Ive had skin problems where I needed to scratch. Now, I found a lump in my upper thigh and its the size of a quarter. I can only notice it when I touch it and it feels like Im pressing against another bruise. However nothing has appeared on the skin which is leading me to believe its beneath the skin. Any ideas on what it could be?\"), dtype=torch.long)\n",
        "context = data.reshape(-1, 1).to(device)\n",
        "output=decodeText(m.generate(context, maxNewTokens=1000)[0].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC4-IKQ-Vl-p"
      },
      "outputs": [],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgTl0SQdepby"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
